
# 企业日志分析平台（ELK）搭建
本文基于Linux系统运维实战，详细讲解企业级日志分析平台的核心概念、主流ELK架构组成及完整部署配置流程，包括日志基础分类、ELK各组件作用、一站式部署步骤、系统日志收集展示及Kibana安全认证配置，适配企业服务器应用集群的日志集中管理需求。

## 一、日志基础认知
在企业复杂的服务器应用集群中，日志类型多样、记录方式不一，导致问题排查效率低，**集中式日志分析平台**是解决该问题的核心方案，先明确日志的基础分类与级别标准。
### 1.1 日志分类
日志主要分为**系统日志**和**应用服务日志**两类，覆盖企业服务器与应用的全量运行记录：
- **系统日志**：记录服务器硬件、系统软件的运行信息，以及系统运行过程中的各类事件（如开机、进程启停、硬件故障等），是运维人员排查系统级故障的核心依据。
- **应用服务日志**：记录各类应用在启动、运行、调试过程中的专属信息，典型如Nginx反向代理日志、Tomcat容器日志、企业自研业务APP运行日志等，用于排查应用层问题。

### 1.2 日志级别
日志按**严重程度从低到高**分为5个级别，不同级别对应不同的问题排查价值，企业可根据需求筛选指定级别日志进行监控分析：
1. **debug（调试级）**：所有调试过程的详细信息集合，主要用于开发/运维人员调试程序，生产环境一般不开启全量debug日志。
2. **info（信息级）**：记录软件正常运行的关键节点信息（如应用启动成功、接口正常调用等），用于确认系统/应用的正常运行状态。
3. **warning（警告级）**：系统/应用运行中出现的非致命性异常信息（如资源使用率偏高、配置项非最优等），需关注但不影响当前运行。
4. **error（错误级）**：系统/应用运行中出现的致命性单节点错误（如接口调用失败、文件读写错误等），会导致部分功能异常，需及时排查。
5. **critical/fatal（严重错误级）**：系统/应用出现的全局性严重错误，直接导致软件无法继续运行（如数据库连接失败、核心进程崩溃等），需紧急处理。

## 二、ELK日志系统核心介绍
ELK是目前企业最主流的开源日志分析平台解决方案，由**Elasticsearch、Logstash、Kibana**三个开源组件组成，各组件分工协作，实现日志的**收集→过滤→存储→分析→展示**全流程管理，且支持多场景定制化配置。
### 2.1 ELK各组件核心职责与特性
三个组件各司其职，形成完整的日志处理链路，核心特性与作用如下：

| 组件 | 核心定位 | 关键特性 | 核心作用 |
|------|----------|----------|----------|
| Elasticsearch | 分布式搜索/存储引擎 | 基于Lucene、分布式部署、零配置自动发现、索引分片/副本、RESTful接口、实时搜索、Java开发 | 接收Logstash处理后的日志，以**索引**形式分布式存储，提供高效的日志检索、查询能力 |
| Logstash | 日志收集/过滤/处理工具 | 完全开源、支持多数据源采集、C/S架构、内置过滤分析功能、支持多输出端 | 从各服务器/应用收集原始日志，进行过滤、清洗、格式化处理后，统一发送至Elasticsearch存储 |
| Kibana | 日志可视化展示工具 | 基于Web界面、开源免费、与Elasticsearch深度集成、支持图表/报表/实时监控 | 作为Elasticsearch的前端，将存储的日志以可视化形式展示（如柱状图、折线图、日志列表），支持日志检索、分析、告警配置 |

**核心架构逻辑**：Logstash（客户端）部署在各日志产生节点，收集日志并处理后发送至Logstash服务端，再由服务端统一转发至Elasticsearch存储；运维人员通过KibanaWeb界面连接Elasticsearch，实现日志的可视化查询与分析。

### 2.2 ELK部署前提
ELK三个组件均基于Java开发（Kibana依赖Node.js，底层仍需Java环境支撑），**部署前必须先安装并配置JDK环境**，本文采用JDK 1.8.0_201版本（适配ELK 6.5.0版本，ELK组件建议使用相同版本，避免兼容性问题）。

## 三、ELK日志系统完整部署步骤（CentOS7环境）
本文采用**单服务器一站式部署**（ELK三组件安装在同一台服务器），**生产环境建议分开部署**（各组件独立服务器，提升性能与稳定性），部署版本统一为**6.5.0**，服务器测试地址为`192.168.1.20`。
### 3.1 步骤1：JDK环境安装与配置
1. 解压JDK安装包至指定目录：
    ```bash
    [root@Centos7 ~]# tar zxf jdk-8u201-linux-x64.tar.gz -C /usr/local/
    ```
2. 创建软链接，简化JDK路径调用：
    ```bash
    [root@Centos7 ~]# ln -s /usr/local/jdk1.8.0_201 /usr/local/jdk
    ```
3. 配置系统环境变量，写入`/etc/profile`：
    ```bash
    [root@Centos7 ~]# cat >>/etc/profile<<EOF
    JAVA_HOME=/usr/local/jdk
    CLASSPATH=.:\${JAVA_HOME}/lib:/dt.jar:\${JAVA_HOME}/lib/tools.jar
    PATH=\$PATH:\${JAVA_HOME}/bin
    EOF
    ```
4. 生效环境变量并验证安装：
    ```bash
    [root@Centos7 ~]# source /etc/profile
    [root@Centos7 ~]# java -version
    ```
   出现`java version "1.8.0_201"`相关提示，说明JDK环境配置完成。

### 3.2 步骤2：Elasticsearch安装与启动
1. 解压安装包并创建软链接：
    ```bash
    [root@Centos7 ~]# tar zxf elasticsearch-6.5.0.tar.gz -C /usr/local/
    [root@Centos7 ~]# ln -s /usr/local/elasticsearch-6.5.0 /usr/local/elasticsearch
    ```
2. 修改核心配置文件`elasticsearch.yml`，指定数据/日志存储路径、网络访问规则：
    ```bash
    [root@Centos7 ~]# vim /usr/local/elasticsearch/config/elasticsearch.yml
    ```
   关键配置项（其余默认）：
    ```yaml
    # 数据存储路径
    path.data: /data/elasticsearch/data
    # 日志存储路径
    path.logs: /data/elasticsearch/logs
    # 允许所有IP访问
    network.host: 0.0.0.0
    # 默认通信端口
    http.port: 9200
    ```
3. 创建专用用户`elk`（Elasticsearch禁止root用户启动），并授权目录权限：
    ```bash
    [root@Centos7 ~]# useradd elk
    [root@Centos7 ~]# passwd elk # 设置密码
    [root@Centos7 ~]# chown -R elk.elk /data/elasticsearch/
    [root@Centos7 ~]# chown -R elk.elk /usr/local/elasticsearch/
    ```
4. 切换至elk用户，启动Elasticsearch并验证：
    ```bash
    [root@Centos7 ~]# su - elk
    [elk@Centos7 ~]$ /usr/local/elasticsearch/bin/elasticsearch &
    # 验证端口监听（9200为HTTP端口，9300为节点通信端口）
    [elk@Centos7 ~]$ ss -lntupl | grep 9200
    # 验证服务可用性
    [elk@Centos7 ~]$ curl http://192.168.1.20:9200
    ```
   出现集群名称、版本、UUID等信息，说明Elasticsearch启动成功。

### 3.3 步骤3：Logstash安装与测试
1. 解压安装包并创建软链接：
    ```bash
    [root@Centos7 ~]# tar zxf logstash-6.5.0.tar.gz -C /usr/local/
    [root@Centos7 ~]# ln -s /usr/local/logstash-6.5.0 /usr/local/logstash
    ```
2. 创建测试配置文件`test.conf`，验证Logstash的输入/输出功能：
    ```bash
    [root@Centos7 ~]# vim /usr/local/logstash/config/test.conf
    ```
   测试配置（标准输入→标准输出，格式化展示）：
    ```conf
    input {
      stdin() # 从控制台输入
    }
    output {
      stdout { codec => rubydebug } # 控制台输出，rubydebug格式美化
    }
    ```
3. 启动Logstash并测试：
    ```bash
    [root@Centos7 ~]# cd /usr/local/logstash/
    [root@Centos7 logstash]# ./bin/logstash -f ./config/test.conf
    ```
   控制台输入`welcome to here!`，若返回包含`message、host、@timestamp`的格式化日志信息，说明Logstash安装成功。

### 3.4 步骤4：Kibana安装与启动
1. 解压安装包并创建软链接：
    ```bash
    [root@Centos7 ~]# tar zxf kibana-6.5.0-linux-x86_64.tar.gz -C /usr/local/
    [root@Centos7 ~]# ln -s /usr/local/kibana-6.5.0-linux-x86_64 /usr/local/kibana
    ```
2. 备份并修改配置文件`kibana.yml`，指定端口、访问IP、Elasticsearch地址：
    ```bash
    [root@Centos7 ~]# cd /usr/local/kibana/config
    [root@Centos7 config]# cp kibana.yml kibana.yml.old # 备份原配置
    [root@Centos7 config]# vim kibana.yml
    ```
   关键配置项：
    ```yaml
    # Kibana Web端口
    server.port: 5601
    # 允许所有IP访问
    server.host: "0.0.0.0"
    # 连接的Elasticsearch地址
    elasticsearch.url: "http://192.168.1.20:9200"
    ```
3. 启动Kibana并验证：
    ```bash
    [root@Centos7 config]# /usr/local/kibana/bin/kibana &
    # 验证端口监听
    [root@Centos7 config]# ss -lntupl | grep 5601
    ```
   打开浏览器，输入`http://192.168.1.20:5601`，出现Kibana欢迎页面，说明启动成功。

## 四、ELK实现系统日志收集与可视化展示
完成ELK三组件安装后，需配置Logstash的**日志采集规则**和Kibana的**索引配置**，实现从Linux系统日志采集到可视化展示的全流程，本文以采集CentOS7系统核心日志`/var/log/messages`为例。
### 4.1 步骤1：配置Logstash采集系统日志
修改Logstash的`test.conf`配置文件，将**输入源改为系统日志文件**，**输出源改为Elasticsearch**：
```bash
[root@Centos7 ~]# vim /usr/local/logstash/config/test.conf
```
配置内容：
```conf
input {
  file {
    type => "test" # 标记日志类型，便于分类
    path => "/var/log/messages" # 系统日志路径
    start_position => "beginning" # 从日志文件开头开始采集
  }
}
output {
  elasticsearch {
    hosts => ["192.168.1.20:9200"] # Elasticsearch地址
    action => "index" # 执行索引操作
    index => "test-%{+YYYY-MM-dd}" # 按日期创建索引，便于日志归档
  }
}
```
重启Logstash使配置生效：
```bash
[root@Centos7 ~]# /usr/local/logstash/bin/logstash -f ./config/test.conf &
```
此时Logstash会持续采集`/var/log/messages`中的日志，处理后发送至Elasticsearch，自动创建按日期命名的索引（如`test-2019-03-17`）。

### 4.2 步骤2：Kibana创建索引并展示日志
1. 打开Kibana Web界面（`http://192.168.1.20:5601`），进入**Index Patterns**（索引模式）模块，点击**Create index pattern**；
2. 输入索引名称匹配规则（如`test-*`），匹配Logstash创建的所有系统日志索引，完成第一步定义；
3. 选择时间字段为`@timestamp`（Logstash自动添加的日志时间戳），完成第二步配置；
4. 点击**Create index pattern**创建索引，进入**Discover**模块，即可看到`/var/log/messages`中的系统日志实时展示，支持按时间、关键词、日志级别等条件检索过滤。

## 五、Kibana登录认证配置（企业生产环境必备）
默认情况下Kibana无登录验证，任何人得知服务器地址和端口即可访问，存在严重的信息安全风险。**企业生产环境中通过Nginx反向代理为Kibana添加HTTP基础认证**，是最常用、最简便的安全方案。
### 5.1 步骤1：安装依赖工具与创建认证密码
1. 安装Apache密码生成工具`httpd-tools`，用于生成用户认证密码文件：
    ```bash
    [root@Centos7 ~]# yum install httpd-tools -y
    ```
2. 创建密码存储目录，生成认证密码文件（用户名`admin`，密码`admin123`，可自定义）：
    ```bash
    [root@Centos7 ~]# mkdir -p /kibana/password
    [root@Centos7 ~]# cd /kibana/password/
    [root@Centos7 password]# htpasswd -c -b kibana.passwd admin admin123
    ```
   其中`-c`表示创建新文件，`-b`表示直接输入用户名和密码。

### 5.2 步骤2：配置Nginx反向代理与认证
1. 安装并启动Nginx（若已安装可跳过，配置前需验证Nginx配置文件语法）；
2. 修改Nginx主配置文件`nginx.conf`，添加Kibana代理配置：
    ```bash
    [root@Centos7 ~]# vim /usr/local/nginx/conf/nginx.conf
    ```
   在`http`模块中添加server节点：
    ```nginx
    server {
      listen 80; # Nginx监听端口
      server_name localhost; # 服务器域名/IP
      location / {
        auth_basic "kibana login auth"; # 认证提示语
        auth_basic_user_file /kibana/password/kibana.passwd; # 认证密码文件路径
        proxy_pass http://192.168.1.20:5601; # 反向代理至Kibana地址
        proxy_redirect off; # 关闭重定向
        index index.html index.htm;
      }
    }
    ```
3. 验证Nginx配置并启动：
    ```bash
    [root@Centos7 ~]# /usr/local/nginx/sbin/nginx -t # 验证语法
    [root@Centos7 ~]# /usr/local/nginx/sbin/nginx # 启动Nginx
    ```

### 5.3 步骤3：验证认证效果
打开浏览器，输入**Nginx地址**`http://192.168.1.20`（而非原Kibana地址`5601`端口），浏览器会弹出登录框，输入配置的用户名`admin`和密码`admin123`，即可成功进入Kibana界面；若密码错误则无法访问，实现登录认证管控。

## 六、企业生产环境扩展说明
本文实现的是ELK日志平台的**基础部署与配置**，满足企业日志集中收集、展示的基本需求，在实际生产环境中，还可根据企业需求进行以下扩展优化：
1. **分布式部署**：将Logstash客户端部署在所有日志产生节点（如Web服务器、数据库服务器、应用服务器），Logstash服务端、Elasticsearch、Kibana分别部署在独立服务器，提升日志采集效率和平台稳定性；
2. **日志过滤优化**：在Logstash中添加`filter`模块，对原始日志进行清洗（如剔除无用信息、提取关键字段、按日志级别过滤），减少Elasticsearch存储压力；
3. **Elasticsearch集群**：搭建Elasticsearch集群，配置主节点、数据节点、协调节点，实现日志的分布式存储和负载均衡，提升检索性能；
4. **日志告警**：在Kibana中配置告警规则，对`error/critical`级别日志或指定关键词日志设置邮件/短信告警，实现问题实时感知；
5. **插件扩展**：使用ELK官方插件（如Filebeat、Metricbeat），Filebeat可替代Logstash客户端实现轻量级日志采集（资源占用更低），Metricbeat可采集服务器监控指标，实现日志+监控的一体化管理；
6. **权限精细化管控**：基于RBAC模型为Kibana配置多用户、多角色权限，如开发人员仅可查看所属应用的日志，运维人员可查看全量日志并进行配置修改。

至此，一套完整的企业级ELK日志分析平台就部署配置完成，可实现企业服务器与应用日志的集中收集、存储、分析和可视化展示，大幅提升问题排查效率，为企业系统稳定性保驾护航。


